{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+u7QvgYPF1ueR0oFgEc8v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Fatbox for numerical modelling - correlation\n","\n","The following IPython notebook detail the workflow used to **correlate faults** in the **numerical modelling** application of Fatbox paper. The process is the same used by Derek Neuharth in his study (he kindly agreed for the diffusion of the code).\n","\n","The 2D continental rifting model was made using the geodynamic code ASPECT coupled to the landscape evolution code FastScape. This model simulates a continental rift while incorporating sedimentation and erosion processes.\n","\n","In this workflow we use strain data from the cross section view of the model. We show how to **correlate the faults extracted** using Fatbox.\n","This is tutorial 2 of the numerical modelling application.\n","\n","Neuharth, D., Brune, S., Wrona, T., Glerum, A., Braun, J., & Yuan, X. (2022). Evolution of rift systems and their fault networks in response to surface processes. Tectonics, 41, e2021TC007166. https://doi.org/10.1029/2021TC007166"],"metadata":{"id":"cfUvYcIyLqZ6"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zz3ZcPJDKJvI","executionInfo":{"status":"ok","timestamp":1755012250378,"user_tz":-120,"elapsed":1063,"user":{"displayName":"Pauline Gayrin","userId":"16651678554394298099"}},"outputId":"93fa20ad-4afe-40fe-a3c0-8587c8079be4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Fatbox/modules\n"]}],"source":["# COMMENT IF RUNNING OUTSIDE GOOGLE COLAB\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!pwd"]},{"cell_type":"code","source":["# COMMENT IF RUNNING OUTSIDE GOOGLE COLAB\n","!pip install earthpy\n","!pip install cv-algorithms\n","!pip install vtk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UkDVPwoL62L","executionInfo":{"status":"ok","timestamp":1755012266385,"user_tz":-120,"elapsed":14547,"user":{"displayName":"Pauline Gayrin","userId":"16651678554394298099"}},"outputId":"062ae4d0-105f-414e-a6cf-be612b62f67a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: earthpy in /usr/local/lib/python3.11/dist-packages (0.9.4)\n","Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (from earthpy) (1.1.1)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from earthpy) (3.10.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from earthpy) (2.0.2)\n","Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (from earthpy) (1.4.3)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from earthpy) (0.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from earthpy) (2.32.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->earthpy) (2.9.0.post0)\n","Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (0.11.1)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (2.2.2)\n","Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (3.7.1)\n","Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->earthpy) (2.1.1)\n","Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (2.4.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (25.3.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (2025.8.3)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (8.2.1)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (0.7.2)\n","Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio->earthpy) (1.1.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->earthpy) (2.5.0)\n","Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (1.16.1)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (3.5)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (2025.6.11)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->earthpy) (0.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->geopandas->earthpy) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->geopandas->earthpy) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->earthpy) (1.17.0)\n","Requirement already satisfied: cv-algorithms in /usr/local/lib/python3.11/dist-packages (1.1.1)\n","Requirement already satisfied: cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from cv-algorithms) (1.17.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cv-algorithms) (2.0.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from cv-algorithms) (4.12.0.88)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from cv-algorithms) (75.2.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=0.7->cv-algorithms) (2.22)\n","Requirement already satisfied: vtk in /usr/local/lib/python3.11/dist-packages (9.5.0)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from vtk) (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk) (1.17.0)\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import networkx as nx\n","import pickle\n","from scipy.spatial import distance_matrix\n","import pandas as pandas\n","import math\n","from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n","from joblib import Parallel, delayed\n","import multiprocessing\n","import cv2\n","import timeit\n","from tqdm import tqdm\n","from pathlib import Path\n","import os\n","\n","#Paste your own directory\n","path_folder=Path('/content/drive/MyDrive/Fatbox')\n","path_modules=path_folder/'modules'\n","os.chdir(path_modules) # make modules as working directory\n","# on colab in a new cell: print(path_modules) #make sure path_modules = '/Fatbox/modules'\n","# on you IDE: type pwd in console and make sure it is '/Fatbox/modules'\n","\n","# Fatbox import\n","import preprocessing\n","import metrics\n","import plots\n","import utils\n","import structural_analysis\n","import edits\n","\n","\n","data_path=Path(path_folder)/'tutorials'/'num'/'data_num'\n","\n","save_path=Path(path_folder)/'tutorials'/'num'/'plots_num'\n","\n","array_path=Path(path_folder)/'tutorials'/'num'/'array_num'\n"],"metadata":{"id":"dzDfCeIALqyD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's set the parameters\n","The first group of settings are the same as for the extraction\n","\n","Then R is important. The faults are considered similar and correlated when the average distance between them is lower than the set distance R (in pixels).\n","High R values loosen the correlation.\n","Low R values tighten the correlation."],"metadata":{"id":"mnMV3M91Ns0C"}},{"cell_type":"code","source":["# Data from parameter file (=bash file) of the model\n","#endtime=0      # in myr, 0 will take last available time\n","#starttime=0.015  # in myr 0.015\n","x_pixels=2880\n","xlength=450  # in km\n","y_pixels=448\n","strain_rate_factor=0.1\n","minimum_distance=1.5\n","R=5\n","num_proc=12 # number of processor or the computer if using parallelisation\n","min_fault_length=1.5       # in km\n","scale = xlength/x_pixels\n","\n","start=200\n","end=450\n","step=50\n","times = list(range(start, end, step))\n","\n","factor=1\n","\n","R_new = [6,  6, 6] # R in pixel"],"metadata":{"id":"LwVE31bPNr5w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definition of some functions"],"metadata":{"id":"ihuku7LuQur_"}},{"cell_type":"code","source":["\n","### Define functions\n","def get_nodes(G):\n","    labels = metrics.get_fault_labels(G)\n","    point_set=[]\n","    for label in labels:\n","        G_fault = metrics.get_fault(G, label)\n","        points = []\n","        for node in G_fault:\n","            points.append(G_fault.nodes[node]['pos'])\n","        point_set.append(points)\n","    return point_set\n","\n","def is_A_in_B(set_A, set_B, R):\n","      distances = np.zeros((len(set_A), len(set_B)))\n","      for n, pt_0 in enumerate(set_A):\n","          for m, pt_1 in enumerate(set_B):\n","              distances[n,m] = math.sqrt((pt_0[0]-pt_1[0])**2 + (pt_0[1]-pt_1[1])**2)\n","      if np.mean(np.min(distances, axis=1)) > R:\n","          return False\n","      else:\n","          return True\n","\n","def compute_similarity(set_A, set_B):\n","      distances = np.zeros((len(set_A), len(set_B)))\n","      for n, pt_0 in enumerate(set_A):\n","          for m, pt_1 in enumerate(set_B):\n","              distances[n,m] = math.sqrt((pt_0[0]-pt_1[0])**2 + (pt_0[1]-pt_1[1])**2)\n","      return np.mean(np.min(distances, axis=1))\n","\n","def correlation_slow(G_0, G_1, R):\n","    # A function that labels the faults in G_1 according to G_0 using the\n","    # minimum radius R\n","    #R is a measure for the minimal distance between faults to be correlated,\n","    #so higher values loosen the correlation and lower values tighten it.\n","\n","\n","    # Get labels and nodes\n","    fault_labels_0 = metrics.get_fault_labels(G_0)\n","    fault_labels_1 = metrics.get_fault_labels(G_1)\n","\n","    nodes_0 = get_nodes(G_0)\n","    nodes_1 = get_nodes(G_1)\n","\n","\n","    # Compute similarities\n","    #smf stands for forward similarities, smb for backwards similarities\n","    smf = np.zeros((len(fault_labels_0), len(fault_labels_1)))\n","    smb = np.zeros((len(fault_labels_1), len(fault_labels_0)))\n","\n","\n","    for n in tqdm(range(len(fault_labels_0)), desc='   Compute similarities'):\n","        for m in range(len(fault_labels_1)):\n","            smf[n,m] = compute_similarity(nodes_0[n], nodes_1[m])\n","            smb[m,n] = compute_similarity(nodes_1[m], nodes_0[n])\n","\n","\n","    # Determine correlations\n","    #check for Euclidean distance: radius R determines threshold similarity\n","    #correlations stores similar faults for potential renaming in next step\n","    correlations = set()\n","    for n in tqdm(range(len(fault_labels_0)), desc='   Find correlations'):\n","        for m in range(len(fault_labels_1)):\n","            if smf[n,m] < R:\n","                correlations.add((fault_labels_0[n], fault_labels_1[m]))\n","            if smb[m,n] < R:\n","                correlations.add((fault_labels_0[n], fault_labels_1[m]))\n","\n","    return correlations, smf, smb\n","\n","def relabel(G_1, correlations):\n","\n","    # A function, which relabels G_1 using the correlations\n","    for node in G_1:\n","        G_1.nodes[node]['correlated']=0\n","\n","    lengths = [metrics.total_length(metrics.get_fault(G_0, correlation[0])) for correlation in correlations]\n","    lengths, correlations = zip(*sorted(zip(lengths, correlations)))\n","\n","\n","    for node in G_1:\n","        for correlation in correlations:\n","            if G_1.nodes[node]['component'] == correlation[1]:\n","                G_1.nodes[node]['family'].extend([G_1.nodes[node]['fault']])\n","                #remove duplicates\n","                G_1.nodes[node]['family'] = list(set(G_1.nodes[node]['family']))\n","                G_1.nodes[node]['fault'] = correlation[0]\n","                G_1.nodes[node]['correlated'] = 1\n","\n","    max_comp = max(metrics.get_fault_labels(G_1))\n","\n","    G_1_sub = nx.subgraph(G_1, [node for node in G_1 if G_1.nodes[node]['correlated']==0])\n","    for label, cc in enumerate(sorted(nx.connected_components(G_1_sub))):\n","        for n in cc:\n","            G_1.nodes[n]['fault'] = label+max_comp+1\n","\n","    return G_1\n","\n","class fault_database():\n","\n","    def __init__(self):\n","        self.Gs = []\n","        self.times = []\n","        self.matrices = []\n","        self.correlations = []\n","\n","\n","\n","    def add_graph(self, G, time):\n","        self.Gs.append(G)\n","        self.times.append(time)\n","\n","\n","\n","    def replace_graph(self, G, time):\n","        index = 0\n","        for G, t in zip(self.Gs, self.times):\n","            if t == time:\n","                self.Gs[index] = G\n","            index += 1\n","\n","    def get_graphs_by_time(self, times):\n","\n","        if isinstance(times, int):\n","            for G, t in zip(self.Gs, self.times):\n","                if t == times:\n","                    return G\n","\n","        if isinstance(times, list):\n","            Gs = []\n","            for G, t in zip(self.Gs, self.times):\n","                if t in times:\n","                    Gs.append(G)\n","            return Gs\n","\n","\n","def plot_results(G, time):\n","\n","    data = pandas.read_csv(str(data_path)+'/data_' + str(time) + '.csv', delimiter=',')\n","\n","    # Get positions for fields we need.\n","    nps_pos = data.columns.get_loc(\"noninitial_plastic_strain\")\n","\n","    # Convert pandas to numpy.\n","    data = data.to_numpy()\n","    data = np.flip(data, axis=0)\n","\n","    non_strain = data[:,nps_pos].reshape(y_pixels, x_pixels)\n","    non_strain = np.flip(non_strain, axis=1)\n","\n","\n","    Gmaxx = x_pixels\n","    Gminx = 0\n","    Gmaxy = y_pixels\n","    Gminy = 0\n","\n","    maxy = Gmaxy*scale#/1000\n","    maxx = Gmaxx*scale#/1000\n","    minx = Gminx*scale#/1000\n","\n","    xint = 5\n","    if (maxx - minx) < 40:\n","        xint = 5\n","    elif (maxx - minx) < 80:\n","        xint = 10\n","    elif (maxx - minx) < 155:\n","        xint = 25\n","    else:\n","        xint = 50\n","\n","    yint = 5\n","    if (maxy + 10) < 35:\n","        yint = 5\n","    else:\n","        yint = 10\n","\n","    # correct labels of the axis\n","    xlab = np.array(np.zeros(math.floor((maxx-minx)/xint)))\n","    xlab[len(xlab)//2] = math.ceil(minx/xint)*xint\n","    for i in range(1, (len(xlab)//2)+1):\n","        xlab[(len(xlab)//2)-i]=-(xint*i)\n","        xlab[(len(xlab)//2)+i]=+(xint*i)\n","\n","    ylab = np.array(np.zeros(math.floor((maxy+10)/yint)))\n","    ylab[0] = -10\n","    for i in range(2, len(ylab)):\n","        ylab[i] = ylab[i-1] + yint\n","\n","    fig, axs = plt.subplots(1, 1, figsize=(16,8))\n","    p = axs.imshow(non_strain, cmap='gray_r',aspect=\"equal\")\n","\n","    plots.plot_faults(G, ax=axs, node_size=0.8, label=True)\n","\n","    listx_G=[]\n","    for node in G.nodes:\n","        listx_G.append(G.nodes[node]['x'])\n","\n","    #axs.set_xlim([Gminx, Gmaxx])\n","    #axs.set_xlim([Gminx, Gmaxx])\n","    axs.set_xlim([1000, 2000])\n","    axs.set_ylim([Gmaxy, 0])\n","    #axs[0].set_title('Non-initial plastic strain, Time: ' + str(title_time) + ' Myr, File:' +str(file), fontweight='bold')\n","    axs.set_title(str('Non-initial plastic strain with faults correlated' + 'time='+str(time)), fontweight='bold')\n","    axs.set_ylabel('Depth (km)')\n","    axs.set_xlabel('Distance from model center (km)')\n","    axs.xaxis.tick_top()\n","\n","    locs_y=ylab/scale #locs in pixels of the labels.\n","    #plt.yticks(locs_y,ylab)\n","\n","    locs_x=(xlab+max(xlab))/scale\n","    #plt.xticks(locs_x,xlab)\n","\n","    plt.savefig(save_path/'correlated'/str('image_' + str(time) + '.png'), dpi=200)\n","    #plt.savefig(save_path / str('image_' + str(file).zfill(5) +'.png'), dpi=200)\n","\n","    plt.close(\"all\")\n","\n","def get_nonstrain(time):\n","    data = pandas.read_csv(str(data_path)+'/data_' + str(time) + '.csv', delimiter=',')\n","\n","    # Get positions for fields we need.\n","    nps_pos = data.columns.get_loc(\"noninitial_plastic_strain\")\n","\n","    # Convert pandas to numpy.\n","    data = data.to_numpy()\n","    data = np.flip(data, axis=0)\n","\n","    non_strain = data[:,nps_pos].reshape(y_pixels, x_pixels)\n","    non_strain = np.flip(non_strain, axis=1)\n","\n","    return non_strain\n"],"metadata":{"id":"6KW9STCPQuMu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the Graph stored after the extraction."],"metadata":{"id":"g0f_MAOKRkJ_"}},{"cell_type":"code","source":["#Load the networks\n","FD = fault_database()\n","\n","for time in tqdm(times, desc='Load graphs'):\n","    G = pickle.load(open((array_path/str('G'+ str(time)+'.pickle')), 'rb'))\n","    if nx.is_empty(G):\n","        times.remove(time)\n","        # print('Removed time ' + str(time))\n","    else:\n","        FD.add_graph(G, time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hyjvrpDgRfY1","executionInfo":{"status":"ok","timestamp":1755012368278,"user_tz":-120,"elapsed":2090,"user":{"displayName":"Pauline Gayrin","userId":"16651678554394298099"}},"outputId":"cbeee286-b3fa-4511-832f-3400df4928cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Load graphs: 100%|██████████| 5/5 [00:02<00:00,  2.40it/s]\n"]}]},{"cell_type":"markdown","source":["The fault extraction assign arbitray labels to every time steps independently. But to follow the evolution of a fault. it needs to be identified by the same label (the same name if you want) during the whole workflow. This is the goal of the correlation.\n"],"metadata":{"id":"qhX0PjbzR7gH"}},{"cell_type":"markdown","source":["## Correlation between two time steps\n","For more details about the correlation. See the step by step made by Thilo Wrona https://github.com/thilowrona/fatbox_tutorials/tree/main/Numerical_models\n","Fatbox library has been much enlarged since his published version but the principle and the correlation_slow function remain unchanged.\n"],"metadata":{"id":"JjW1iLyCnHRA"}},{"cell_type":"markdown","source":["## Correlation to n+2 and n-2\n","\n","For every timestep (times[n]), the faults are compared to all the faults of the following timestep (times[n+1]) and the timestep after  (times[n+2]) forward correlation. The idea is to identify that fault in the following timesteps as the same structure that evolved and is maybe a bit longer for example. Once recognized based on the best similarity, the fault is relabeled according to the previous timestep. This comparison with 2 timestep ahead insure to take into account small scale variations of the networks. Respectively, the correlation is also made backward, 1 and 2 timesteps before, to ensure consistency of the labels."],"metadata":{"id":"MwEZH0HLm6uI"}},{"cell_type":"code","source":["\n","### Time stepping\n","for n, time in enumerate(times[:-2]): #we need to stop 2 steps before end for upwind comparison\n","\n","\n","    print('\\nTime step = ' + str(times[n]))\n","\n","    if n == 0:\n","        G_0 = FD.get_graphs_by_time(times[n])\n","        for node in G_0:\n","            G_0.nodes[node]['fault'] = G_0.nodes[node]['component']\n","            #initialise family with empty set\n","            G_0.nodes[node]['family'] = []\n","\n","        FD.replace_graph(G_0, times[n])\n","\n","    else:\n","        G_0 = FD.get_graphs_by_time(times[n])\n","\n","\n","    G_1 = FD.get_graphs_by_time(times[n+1])\n","    G_2 = FD.get_graphs_by_time(times[n+2])\n","\n","    for node in G_1:\n","        G_1.nodes[node]['fault'] = G_1.nodes[node]['component']\n","        #initialise family with empty set\n","        G_1.nodes[node]['family'] = []\n","\n","    for node in G_2:\n","        G_2.nodes[node]['fault'] = G_2.nodes[node]['component']\n","        #initialise family with empty set\n","        G_2.nodes[node]['family'] = []\n","\n","    fig, axs = plt.subplots(2, 3, figsize=(19.2,10),num=str(times[n])+' R='+str(R_new[n]))\n","\n","    axs[0,0].imshow(get_nonstrain(times[n]), cmap='gray_r',aspect=\"equal\")\n","    axs[0,0].set_title('raw' + str(times[n]))\n","    axs[0,0].set_xlim([1000, 2000])\n","    axs[0,0].set_ylim([y_pixels, 0])\n","\n","    axs[0,1].imshow(get_nonstrain(times[n+1]), cmap='gray_r',aspect=\"equal\")\n","    axs[0,1].set_title('raw' + str(times[n+1]))\n","    axs[0,1].set_xlim([1000, 2000])\n","    axs[0,1].set_ylim([y_pixels, 0])\n","\n","    axs[0,2].imshow(get_nonstrain(times[n+2]), cmap='gray_r',aspect=\"equal\")\n","    axs[0,2].set_title('raw' + str(times[n+2]))\n","    axs[0,2].set_xlim([1000, 2000])\n","    axs[0,2].set_ylim([y_pixels, 0])\n","\n","    plots.plot_faults(G_0, node_size=2, ax=axs[0,0])\n","    plots.plot_faults(G_1, node_size=2, ax=axs[0,1])\n","    plots.plot_faults(G_2, node_size=2, ax=axs[0,2])\n","\n","\n","    ########## FIRST CORRELATION\n","    correlations01, smf01, smb01 = correlation_slow(edits.simplify(G_0, factor),\n","                                                    edits.simplify(G_1, factor),\n","                                                    R_new[n])\n","    G_1 = relabel(G_1, correlations01)\n","\n","\n","    axs[1,0].imshow(get_nonstrain(times[n]), cmap='gray_r',aspect=\"equal\")\n","    axs[1,0].set_title('raw' + str(times[n]))\n","    axs[1,0].set_xlim([1000, 2000])\n","    axs[1,0].set_ylim([y_pixels, 0])\n","\n","    axs[1,1].imshow(get_nonstrain(times[n+1]), cmap='gray_r',aspect=\"equal\")\n","    axs[1,1].set_title('1st correlation: ' + str(times[n+1]) + ' using '+ str(times[n]))\n","    axs[1,1].set_xlim([1000, 2000])\n","    axs[1,1].set_ylim([y_pixels, 0])\n","\n","    plots.plot_faults(G_0, node_size=2, ax=axs[1,0])\n","    plots.plot_faults(G_1, node_size=2, ax=axs[1,1])\n","\n","    #plt.show()\n","\n","    if n == 0:\n","        FD.replace_graph(G_1, times[n+1])\n","\n","        plot_results(G_1, times[n+1])\n","\n","\n","    # # SECOND CORRELATION\n","    correlations02, smf02, smb02 = correlation_slow(edits.simplify(G_0, factor),\n","                                                    edits.simplify(G_2, factor),\n","                                                    R_new[n])\n","\n","    G_2 = relabel(G_2, correlations02)\n","\n","    for node in G_2:\n","        G_2.nodes[node]['component'] = G_2.nodes[node]['fault']\n","\n","\n","    correlations12, smf12, smb12 = correlation_slow(edits.simplify(G_1, factor),\n","                                                    edits.simplify(G_2, factor),\n","                                                    R_new[n])\n","\n","    G_2 = relabel(G_2, correlations12)\n","\n","\n","    axs[1,2].imshow(get_nonstrain(times[n+2]), cmap='gray_r',aspect=\"equal\")\n","    axs[1,2].set_title('2d correlation: ' + str(times[n+2]) + ' using '+ str(times[n]))\n","    axs[1,2].set_xlim([1000, 2000])\n","    axs[1,2].set_ylim([y_pixels, 0])\n","\n","    plots.plot_faults(G_2, node_size=2, ax=axs[1,2])\n","\n","    plt.tight_layout()\n","\n","    plt.savefig(Path(save_path)/'correlated'/str('progressive_corr_' + str(time) + '.png'), dpi=200)\n","\n","    plot_results(G_2, times[n+2])\n"],"metadata":{"id":"sJxAYjYzRvSn","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1754923393035,"user_tz":-120,"elapsed":222,"user":{"displayName":"Pauline Gayrin","userId":"16651678554394298099"}},"outputId":"2bca8e20-c9f1-4bc7-d51b-1da00552f8f4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'times' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1829564965.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m### Time stepping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#we need to stop 2 steps before end for upwind comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'times' is not defined"]}]}]}